{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from rnn.ipynb\n",
      "importing Jupyter notebook from retain.ipynb\n",
      "importing Jupyter notebook from retain_bkey.ipynb\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.nn.utils.rnn import pack_sequence\n",
    "\n",
    "import import_ipynb\n",
    "\n",
    "from datetime import datetime\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "\n",
    "from rnn import RNN\n",
    "from retain import RETAIN\n",
    "from retain_bkey import RETAIN_BKEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsing():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--cuda', action='store_true',\n",
    "                        help='use CUDA (default: False)')\n",
    "    parser.add_argument('--eval', action='store_true',\n",
    "                        help='do evaluate (default: False)')\n",
    "    parser.add_argument('--dropout', type=float, default=0.5,\n",
    "                        help='dropout applied to layers (default: 0)')\n",
    "    parser.add_argument('--clip', type=float, default=-1,\n",
    "                        help='gradient clip, -1 means no clip (default: -1)')\n",
    "    parser.add_argument('--epochs', type=int, default=500,\n",
    "                        help='upper epoch limit (default: 500)')\n",
    "    parser.add_argument('--report_step', type=int, default=1, metavar='N',\n",
    "                        help='report interval (default: 20')\n",
    "    parser.add_argument('--valid_step', type=int, default=1, metavar='N',\n",
    "                        help='validation interval (default: 20')\n",
    "    parser.add_argument('--lr', type=float, default=0.0001,\n",
    "                        help='initial learning rate (default: 1e-3)')\n",
    "    parser.add_argument('--optim', type=str, default='Adam',\n",
    "                        help='optimizer to use (default: Adam)')\n",
    "    parser.add_argument('--batchs', type=int, default=16,\n",
    "                        help='number of batchs (default: 10)')\n",
    "    parser.add_argument('--val_batchs', type=int, default=32,\n",
    "                        help='number of batchs (default: 10)')\n",
    "    parser.add_argument('--train_data', type=str, default='data/physionet-a/train')\n",
    "    parser.add_argument('--dev_data', type=str, default='data/physionet-a/dev')\n",
    "    parser.add_argument('--test_data', type=str, default='data/physionet-a/test')\n",
    "    parser.add_argument('--seed', type=int, default=190408,\n",
    "                        help='random seed')\n",
    "    parser.add_argument('--model_name', type=str, default='AP',\n",
    "                        help='the dataset to run (default: )')\n",
    "    parser.add_argument('--embedding_size', type=int, default=128,\n",
    "                        help='dimension of embeddings')\n",
    "    parser.add_argument('--hidden_size', type=int, default=128,\n",
    "                        help='dimension of hidden')\n",
    "    return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_nparr2torchtensor(t, rev=True):\n",
    "    out = t[:]\n",
    "    if rev:\n",
    "        for idx, elm in enumerate(t):\n",
    "            out[len(t)-idx-1] = torch.Tensor(elm)\n",
    "    else:\n",
    "        for idx, elm in enumerate(t):\n",
    "            out[idx] = torch.Tensor(elm)   \n",
    "    return out\n",
    "\n",
    "def load_data(args):\n",
    "    x_train = convert_nparr2torchtensor(np.load(args.train_data + '.x.npy'))\n",
    "    y_train = convert_nparr2torchtensor(np.load(args.train_data + '.y.npy'))\n",
    "    assert len(x_train) == len(y_train)\n",
    "    x_dev = convert_nparr2torchtensor(np.load(args.dev_data + '.x.npy'))\n",
    "    y_dev = convert_nparr2torchtensor(np.load(args.dev_data + '.y.npy'))\n",
    "    assert len(x_dev) == len(y_dev)\n",
    "    x_test = convert_nparr2torchtensor(np.load(args.test_data + '.x.npy'))\n",
    "    y_test = convert_nparr2torchtensor(np.load(args.test_data + '.y.npy'))\n",
    "    assert len(x_test) == len(y_test)\n",
    "    return x_train, y_train, x_dev, y_dev, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(args):\n",
    "    model = None\n",
    "    if args.model_name == 'RNN':\n",
    "        #input_size, embedding_size, hidden_size, output_size\n",
    "        model = RNN(args.input_size, args.embedding_size, args.hidden_size, args.output_size, \n",
    "                    dropout=args.dropout)\n",
    "    elif args.model_name == 'RETAIN':\n",
    "        #input_size, embedding_size, hidden_size, output_size\n",
    "        model = RETAIN(args.input_size, args.embedding_size, args.hidden_size, args.output_size, \n",
    "                    dropout=args.dropout)\n",
    "    elif args.model_name == 'RETAIN_BKEY':\n",
    "        #input_size, embedding_size, hidden_size, output_size\n",
    "        model = RETAIN_BKEY(args.input_size, args.embedding_size, args.hidden_size, args.output_size, \n",
    "                    dropout=args.dropout)\n",
    "    else:\n",
    "        print('No such model name')\n",
    "        exit()\n",
    "    return model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch_index(total_length, batch_size, do_shuffle = True):\n",
    "    train_idx_list = np.arange(total_length)\n",
    "    if do_shuffle:\n",
    "        np.random.shuffle(train_idx_list)\n",
    "    batch_indices = []\n",
    "    for i in range((total_length // batch_size)+1):\n",
    "        start_idx = i*batch_size\n",
    "        end_idx = min(total_length, (i+1)*batch_size)\n",
    "        if start_idx == end_idx:\n",
    "            break\n",
    "        sub_indices = train_idx_list[start_idx : end_idx]\n",
    "        if len(sub_indices) > 0:\n",
    "            batch_indices.append(sub_indices)\n",
    "    return batch_indices\n",
    "    \n",
    "def get_paded_seq(x):\n",
    "    x = list(x)\n",
    "    x.sort(key=lambda element: -element.shape[0])\n",
    "    lengths = [ele.shape[0] for ele in x]\n",
    "    batches = pad_sequence(x, batch_first=True)\n",
    "    return torch.Tensor(batches), torch.Tensor(lengths)\n",
    "    \n",
    "def train_per_epoch(model, batch_size, x_train, y_train, criterion, cuda_on=True):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    count = len(x_train)\n",
    "    batch_indices = generate_batch_index(count, batch_size)\n",
    "    for idx_list in batch_indices:\n",
    "        x, lengths = get_paded_seq(x_train[idx_list])\n",
    "        x = Variable(x)\n",
    "        y = Variable(torch.Tensor(y_train[idx_list]))\n",
    "        if cuda_on:\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "            lengths = lengths.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x, lengths)\n",
    "        reg_loss = None\n",
    "        for param in model.parameters():\n",
    "            if reg_loss is None:\n",
    "                reg_loss = 0.5 * torch.sum(param**2)\n",
    "            else:\n",
    "                reg_loss = reg_loss + 0.5 * param.norm(2)**2\n",
    "\n",
    "        loss = criterion(output, y) #+ reg_loss * 0.0001\n",
    "\n",
    "        total_loss += loss.item() /count\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, batch_size, x_dev, y_dev, criterion, cuda_on=True):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    count = len(x_dev)\n",
    "    batch_indices = generate_batch_index(count, batch_size, do_shuffle = False)\n",
    "    with torch.no_grad():\n",
    "        for idx_list in batch_indices:\n",
    "            x, lengths = get_paded_seq(x_dev[idx_list])\n",
    "            x = Variable(x)\n",
    "            y = Variable(torch.Tensor(y_dev[idx_list]))\n",
    "            if cuda_on:\n",
    "                x, y = x.cuda(), y.cuda()\n",
    "                lengths = lengths.cuda()\n",
    "            output = model(x, lengths)\n",
    "            loss = criterion(output, y)\n",
    "            total_loss += loss.item() \n",
    "        eval_loss = total_loss / count\n",
    "        return eval_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ROC_AUC(p, y): \n",
    "    auc_s = roc_auc_score(y, p)\n",
    "    return auc_s\n",
    "\n",
    "def evaluate(model, batch_size, x_test, y_test, criterion, cuda_on=True):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    count = len(x_test)\n",
    "    batch_indices = generate_batch_index(count, batch_size, do_shuffle = False)\n",
    "    pred = torch.Tensor([])\n",
    "    with torch.no_grad():\n",
    "        for idx_list in batch_indices:\n",
    "            x, lengths = get_paded_seq(x_test[idx_list])\n",
    "            x = Variable(x)\n",
    "            if cuda_on:\n",
    "                x = x.cuda()\n",
    "                lengths = lengths.cuda()\n",
    "            output = model(x, lengths)\n",
    "            output = output.cpu()\n",
    "            pred = torch.cat([pred, output])\n",
    "        pred = pred.squeeze().numpy()\n",
    "        #p = pred.argsort()\n",
    "        #pred = pred[p]\n",
    "        #y_test = y_test[p]\n",
    "        return ROC_AUC(pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019-04-10 11:22:42.813557] Namespace(batchs=16, clip=-1, cuda=True, dev_data='data/physionet-a/dev', dropout=0.5, embedding_size=128, epochs=1, eval=True, hidden_size=128, lr=0.0001, model_name='RETAIN', optim='Adam', report_step=1, seed=190408, test_data='data/physionet-a/test', train_data='data/physionet-a/train', val_batchs=32, valid_step=1)\n",
      "[2019-04-10 11:22:43.275422] #seq: 3200; input dim: 41; output dim: 1;\n",
      "--------------------------------------------------------------------------------\n",
      "[2019-04-10 11:22:45.685639] model: <RETAIN>; lr: <0.00010>; optimizer: <Adam>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\GitHub\\jupyter_test\\retain\\sparsemax.py:54: UserWarning: torch.range is deprecated in favor of torch.arange and will be removed in 0.5. Note that arange generates values in [start; end), not [start; end].\n",
      "  range = torch.range(start=1, end=number_of_logits, device=device).view(1, -1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019-04-10 11:22:56.295245] Step  1/ 1; loss: 0.32595; 10.6s \n",
      "\t Validation loss 0.34830 \n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":  \n",
    "    #parsing\n",
    "    parser = parsing()\n",
    "    args = parser.parse_args(['--cuda', '--eval', '--model_name', 'RETAIN', \n",
    "                              '--epochs', '1', '--lr', '0.0001'])\n",
    "    print('[{:s}]'.format(str(datetime.now())), args)\n",
    "    \n",
    "    #seed\n",
    "    torch.manual_seed(args.seed)\n",
    "    #cuda checking\n",
    "    if torch.cuda.is_available():\n",
    "        if not args.cuda:\n",
    "            print(\"WARNING: Please use a CUDA device. Run with --cuda\")    \n",
    "    \n",
    "    #data load\n",
    "    x_train, y_train, x_dev, y_dev, x_test, y_test = load_data(args)\n",
    "    print('[{:s}] #seq: {:d}; input dim: {:d}; output dim: {:d};'.format(str(datetime.now()), \n",
    "                                                        len(x_train), \n",
    "                                                        x_train[0].shape[1],\n",
    "                                                        y_train[0].shape[0]))\n",
    "    args.input_size = x_train[0].shape[1]\n",
    "    args.output_size = y_train[0].shape[0]\n",
    "    \n",
    "    #model load\n",
    "    model = load_model(args)\n",
    "    if args.cuda:\n",
    "        model.cuda()\n",
    "    \n",
    "    #set optimizer\n",
    "    optimizer = None    \n",
    "    if args.optim == 'Adam' or args.optim == 'RMSprop':\n",
    "        optimizer = getattr(optim, args.optim)(model.parameters(), lr=args.lr)\n",
    "\n",
    "    #set loss\n",
    "    criterion = nn.BCELoss(reduction='sum')\n",
    "    print('-'*80)\n",
    "    \n",
    "    #run training\n",
    "    best_vloss = None\n",
    "    best_ep = 0\n",
    "    model_file = \"./save/{0}.pt\".format(args.model_name)\n",
    "    start_time = datetime.now()\n",
    "    print(\"[{:s}] model: <{:s}>; lr: <{:.5f}>; optimizer: <{:s}>\".format(\n",
    "        str(start_time), args.model_name, args.lr, args.optim))\n",
    "    for ep in range(1, args.epochs+1):\n",
    "        rloss = train_per_epoch(model, args.batchs, x_train, y_train, criterion, cuda_on=True)\n",
    "        \n",
    "        if ep % args.report_step == 0:\n",
    "            now = datetime.now()\n",
    "            dist_time = now - start_time            \n",
    "            print(\"[{:s}] Step {:2d}/{:2d}; loss: {:.5f}; {:.1f}s \".format(str(now), \n",
    "                                                                           ep, \n",
    "                                                                           args.epochs, \n",
    "                                                                           rloss, \n",
    "                                                                           dist_time.total_seconds()))\n",
    "\n",
    "        if ep % args.valid_step == 0:\n",
    "            vloss = validate(model, args.val_batchs, x_dev, y_dev, criterion, cuda_on=True)\n",
    "            print(\"\\t Validation loss {:.5f} \".format(vloss))\n",
    "            if (best_vloss == None) or vloss < best_vloss:\n",
    "                torch.save({'state_dict': model.state_dict()}, model_file)\n",
    "                best_vloss = vloss\n",
    "                best_ep = ep\n",
    "    print('-' * 80)\n",
    "    checkpoint = torch.load(model_file)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best performance: epoch: 1, loss: 0.34830\n",
      "Evaluation- AUC: 0.46404\n"
     ]
    }
   ],
   "source": [
    "    best_vloss = validate(model, args.val_batchs, x_dev, y_dev, criterion, cuda_on=True)\n",
    "    print('Best performance: epoch: {:d}, loss: {:.5f}'.format(best_ep, best_vloss))    \n",
    "    if args.eval:\n",
    "        _auc = evaluate(model, args.val_batchs, x_test, y_test, criterion, cuda_on=True)\n",
    "        print('Evaluation- AUC: {:.5f}'.format(_auc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
